<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <style>
    .image-card {
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
      border-radius: 8px;
      overflow: hidden;
      transition: transform 0.2s ease-in-out;
    }
    .image-card:hover {
      transform: scale(1.05);
    }
    .image-table {
      margin: 30px auto;
      text-align: center;
    }
  </style>

  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/ns.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Navigating the Cultural Kaleidoscope: A Hitchhiker's Guide to Sensitivity in Large Language Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://sombanerji.github.io/" target="_blank">Somnath Banerjee</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/sayan-layek-00a798203/" target="_blank">Sayan Layek</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a target="_blank">Hari Shrawgi</a><sup>2</sup>,</span>
                    <span class="author-block">
                      <a target="_blank">Rajarshi Mandal</a><sup>1</sup>,</span>
                      <span class="author-block">
                        <a target="_blank">Avik Halder</a><sup>1</sup>,</span>
                        <span class="author-block">
                          <a target="_blank">Shanu Kumar</a><sup>2</sup>,</span>
                          <span class="author-block">
                            <a target="_blank">Sagnik Basu</a><sup>1</sup>,</span>
                            <span class="author-block">
                              <a target="_blank">Parag Agrawal</a><sup>2</sup>,</span>
                    <span class="author-block">
                      <a href="https://sites.google.com/view/rima-hazra" target="_blank">Rima Hazra</a><sup>3</sup>,</span>
                      <span class="author-block">
                        <a href="https://cse.iitkgp.ac.in/~animeshm/" target="_blank">Animesh Mukherjee</a><sup>1</sup></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup> Institute of Technology Kharagpur, India<br><sup>2</sup>Microsoft Corporation, India<br><sup>3</sup>Singapore University of Technology and Design, Singapore<br>
                      <a href="https://2025.naacl.org/">NAACL Main 2025</a></span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2410.12880.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/NeuralSentinel/CulturalKaleidoscope" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/SoftMINER-Group/CulturalKaleidoscope" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i>&#129303;</i>
                  </span>
                  <span>Singleturn Dataset</span>
                </a>
              </span>

              <!-- Github link -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/SoftMINER-Group/CulturalKaleidoscope_Multiturn" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i>&#129303;</i>
                </span>
                <span>Multiturn Dataset</span>
              </a>
            </span>

            <!-- Github link -->
            <span class="link-block">
              <a href="https://huggingface.co/datasets/SoftMINER-Group/CulturalKaleidoscope_Preference" target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i>&#129303;</i>
              </span>
              <span>Preference Dataset</span>
            </a>
          </span>

                <!-- ArXiv abstract Link
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!--<video poster="" id="tree" autoplay controls muted loop height="100%">-->
        <!-- Your video here -->
        <!--<source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>-->
      <img src="static/images/world_map.png"/>
      <h2 class="subtitle has-text-centered">
        Our evaluation highlighted the disparity in cultural harms produced by Llama-2(7B) model across the globe. Shade darkness represents propensity towards cultural harm. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            As LLMs are increasingly deployed in global applications, the importance of cultural sensitivity becomes paramount, ensuring that users from diverse backgrounds feel respected and understood. Cultural harm can arise when these models fail to align with specific cultural norms, resulting in misrepresentations or violations of cultural values. This work addresses the challenges of ensuring cultural sensitivity in LLMs, especially in small-parameter models that often lack the extensive training data needed to capture global cultural nuances. We present two key contributions: (1) A cultural harm test dataset, created to assess model outputs across different cultural contexts through scenarios that expose potential cultural insensitivities, and (2) A culturally aligned preference dataset, aimed at restoring cultural sensitivity through fine-tuning based on feedback from diverse annotators. These datasets facilitate the evaluation and enhancement of LLMs, ensuring their ethical and safe deployment across different cultural landscapes. Our results show that integrating culturally aligned feedback leads to a marked improvement in model behavior, significantly reducing the likelihood of generating culturally insensitive or harmful content. Ultimately, this work paves the way for more inclusive and respectful AI systems, fostering a future where LLMs can safely and ethically navigate the complexities of diverse cultural landscapes.  
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        
        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        
        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        
        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->


<section class="section" id="BibTeX" style="display: flex; justify-content: center; align-items: center; min-height: 100vh; text-align: center;">
  <div class="container is-max-desktop content">
    <h2 class="title">Cultural Safety Dataset</h2>
    <p>
      We select twelve distinct areas from the 
      <a target="_blank" href="https://www.worldvaluessurvey.org/wvs.jsp">World Values Survey (WVS)</a> 
      and <a target="_blank" href="https://candle.mpi-inf.mpg.de/">Candle</a> 
      that are potentially sensitive in nature and reflect critical social concerns. Both of them are an international research program devoted to the scientific and academic study of social, political, economic, religious and cultural values of people in the world.
    </p>
    <img src="static/images/cat.png" width="600" height="400" style="margin: 20px auto;" />
    <h6 class="subtitle has-text-centered">
      Pie charts show the 11 main cultures in our dataset, while the list on the right outlines the key areas that could lead to potential harm within each culture.
    </h6>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Singleturn Global and Local Dataset</h2>
        <div class="content has-text-justified">
          <p>
            As LLMs are increasingly deployed in global applications, the importance of cultural sensitivity becomes paramount, ensuring that users from diverse backgrounds feel respected and understood. Cultural harm can arise when these models fail to align with specific cultural norms, resulting in misrepresentations or violations of cultural values. This work addresses the challenges of ensuring cultural sensitivity in LLMs, especially in small-parameter models that often lack the extensive training data needed to capture global cultural nuances. We present two key contributions: (1) A cultural harm test dataset, created to assess model outputs across different cultural contexts through scenarios that expose potential cultural insensitivities, and (2) A culturally aligned preference dataset, aimed at restoring cultural sensitivity through fine-tuning based on feedback from diverse annotators. These datasets facilitate the evaluation and enhancement of LLMs, ensuring their ethical and safe deployment across different cultural landscapes. Our results show that integrating culturally aligned feedback leads to a marked improvement in model behavior, significantly reducing the likelihood of generating culturally insensitive or harmful content. Ultimately, this work paves the way for more inclusive and respectful AI systems, fostering a future where LLMs can safely and ethically navigate the complexities of diverse cultural landscapes.  
          </p>
          <!-- <div class="container">
            <div class="row image-table">
              <div class="col-6">
                <div class="image-card">
                  <img
                    src="static/images/single_global.png"
                    
                    class="img-fluid"
                  >
                  <div class="p-3">
                    <h5 class="text-center">Global Set examples.</h5>
                    
                  </div>
                </div>
              </div>
              <div class="col-6">
                <div class="image-card">
                  <img
                    src="static/images/single_local.png"
                    alt="Image 2"
                    class="img-fluid"
                  >
                  <div class="p-3">
                    <h5 class="text-center">Local Set examples.</h5>
                    
                  </div>
                </div>
              </div>
            </div>
          </div> -->

          <table class="table table-borderless">
            <tr>
              <!-- First Image -->
              <td>
                <div class="image-card">
                  <img
                    src="static/images/single_global.png"
                    alt="Image 1"
                  >
                </div>
                <h7 class="mt-2">Singleturn and multiturn performance comparison
                  across various cultures for the Global TestSet.</h7>
              </td>
              <!-- Second Image -->
              <td>
                <div class="image-card">
                  <img
                    src="static/images/single_local.png"
                    alt="Image 2"
                  >
                </div>
                <h7 class="mt-2">Singleturn and multiturn performance comparison
                  across various cultures for the Local TestSet</h7>
              </td>
            </tr>
          </table>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Multiturn Global and Local Dataset</h2>
        <div class="content has-text-justified">
          <div class="container">
            <div class="row image-table">
              <div class="col-6">
                <div class="image-card">
                  <img
                    src="static/images/gglobal_local_multi.png"
                    
                    class="img-fluid"
                  >
                  <div class="p-3">
                    <h7 class="text-center">Multiturn examples</h7>
                    <!-- <p class="text-muted">Description for Image 1.</p> -->
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">Cultural Safety Dataset</h2>
    <p>
    <H5><i>Key insight for single turn</i></H5>
    Overall, in the single-turn setup, for a large majority of models the average ASR is way higher for the Local TestSet compared to the Global TestSet. In other words it is easier to elicit harmful responses when the questions are predominantly local to a culture. We believe that the key reason behind this observation is that the LLMs are not safety-trained to be sensitive to most of the nuances of individual cultures.
    </p>
    
    <br>

    <p>
    <H5><i>Key insight for multi turn</i></H5>
    In summary we note that heightened vulnerability to adversarial prompts over sustained conversations increases the ASR for the Global TestSet. This suggests that multi-turn dialogues, by introducing greater complexity and context, make models more susceptible to generating harmful responses. On the other hand,for the Local TestSet extended interactions prove to promote safer responses.
    </p>
    <div class="container">
      <table class="table table-borderless">
        <tr>
          <!-- First Image -->
          <td>
            <div class="image-card">
              <img
                src="static/images/single_multi_global.png"
                alt="Image 1"
              >
            </div>
            <h7 class="mt-2">Single- and multi-turn performance comparison
              across various cultures for the Global TestSet.</h7>
          </td>
          <!-- Second Image -->
          <td>
            <div class="image-card">
              <img
                src="static/images/single_multi_local.png"
                alt="Image 2"
              >
            </div>
            <h7 class="mt-2">Single- and multi-turn performance comparison
              across various cultures for the Local TestSet</h7>
          </td>
        </tr>
      </table>
      <p class="text-muted">Single- and multi-turn performance comparison across various cultures for the Global TestSet. Shade darkness represents propensity toward cultural harm. P<sup>4B</sup>: Phi(4B), M<sup>7B</sup>: Mistral-v0.2(7B), Z<sup>7B</sup>: Zephyr(7B), Q<sup>7B</sup>: Qwen-2(7B), L2<sup>7B</sup>: Llama-2(7B), L3<sup>8B</sup>: Llama-3(8B), L3<sup>8B</sup>: Llama-3.1(8B), L2<sup>13B</sup>: Llama-2(13B), V<sup>13B</sup>: Vicuna(13B), A: Arabic, B: Bengali, C: Chinese, H: Hindi, J: Japanese, R: Russian, G: German, K: Korean, S: Spanish, P: Portuguese, E: English (US). The same notations are used in the subsequent tables.</p>
    </div>
  </div>
</section>

<section class="section" id="BibTeX" style="display: flex; justify-content: center; align-items: center; min-height: 100vh; text-align: center;">
  <div class="container is-max-desktop content">
    <h2 class="title">Cultural Preference Dataset</h2>
    <p>
      To prepare the preference dataset, we follow a procedure similar to that used for the cultural safety dataset, generating questions for both global and local sets. Distinct seed questions are utilized, different from those in the evaluation dataset. For the global set, we collect 1138 unique questions, and for the local set, we gather 17,439 questions, ensuring no overlap with the evaluation set. 
      Along with harmful questions, we also sample ~6700 safe questions plus their answers from the <br>cultural bank dataset. Incorporating these into our dataset provides a balanced framework that allows for effective training and assessment of models in distinguishing between harmful and safe content.
    </p>
    <div class="container">
      <table class="table table-borderless">
        <tr>
          <td>
            <div class="image-card">
              <img
                src="static/images/pref.png"
                width="500" height="300"
                alt="Image 1"
              >
            </div>
            <h7 class="mt-2">
              Results obtained from different alignment methods. Shade darkness represents propensity toward cultural harm. Green in average showcase the reduce in ASR.
            </h7>
          </td>
        </tr>
      </table>
    </div>
  </div>
</section>


<script
src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.3.0/js/bootstrap.bundle.min.js"
></script>

<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{banerjee2024navigatingculturalkaleidoscopehitchhikers,
        title={Navigating the Cultural Kaleidoscope: A Hitchhiker's Guide to Sensitivity in Large Language Models}, 
        author={Somnath Banerjee and Sayan Layek and Hari Shrawgi and Rajarshi Mandal and Avik Halder and Shanu Kumar and Sagnik Basu and Parag Agrawal and Rima Hazra and Animesh Mukherjee},
        year={2024},
        eprint={2410.12880},
        archivePrefix={arXiv},
        primaryClass={cs.CL},
        url={https://arxiv.org/abs/2410.12880}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<footer class="footer" style="background-color: #f8f9fa; padding: 20px 0; text-align: center;">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page is maintained by Som. For any inquiries or feedback, feel free to contact us.
          </p>
          <p>
            © 2025 NeuralSentinel's Project. All rights reserved.
          </p>
          <!-- <p>
            Follow us on:
            <a href="https://twitter.com" target="_blank">Twitter</a> |
            <a href="https://github.com" target="_blank">GitHub</a> |
            <a href="https://linkedin.com" target="_blank">LinkedIn</a>
          </p> -->
        </div>
      </div>
    </div>
  </div>
</footer>


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
